{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a59ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d30776f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivatives(x, y):\n",
    "    vx = np.gradient(x)\n",
    "    vy = np.gradient(y)\n",
    "    ax = np.gradient(vx)\n",
    "    ay = np.gradient(vy)\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    accel = np.sqrt(ax**2 + ay**2)\n",
    "    return vx, vy, ax, ay, speed, accel\n",
    "\n",
    "\n",
    "def sliding_window_stats(arr, t, w):\n",
    "    left = max(0, t - w)\n",
    "    right = min(len(arr), t + w + 1)\n",
    "    window = arr[left:right]\n",
    "    return window.mean(), window.std()\n",
    "\n",
    "\n",
    "def build_features(ball_data, windows=(3, 5, 9)):\n",
    "    \"\"\"\n",
    "    Build per-frame features (NO LABEL).\n",
    "    Returns:\n",
    "        X: np.array [n_frames, n_features]\n",
    "        frame_ids: list of frame indices\n",
    "    \"\"\"\n",
    "    frame_ids = sorted(ball_data.keys(), key=lambda x: int(x))\n",
    "    x = np.array([ball_data[f][\"x\"] for f in frame_ids], dtype=float)\n",
    "    y = np.array([ball_data[f][\"y\"] for f in frame_ids], dtype=float)\n",
    "    visible = np.array([ball_data[f][\"visible\"] for f in frame_ids])\n",
    "\n",
    "    # Interpolation simple\n",
    "    idx = np.arange(len(x))\n",
    "    mask = visible & ~np.isnan(x)\n",
    "    x[~mask] = np.interp(idx[~mask], idx[mask], x[mask])\n",
    "    y[~mask] = np.interp(idx[~mask], idx[mask], y[mask])\n",
    "\n",
    "    # Smoothing\n",
    "    if len(x) >= 7:\n",
    "        x = savgol_filter(x, 7, 3)\n",
    "        y = savgol_filter(y, 7, 3)\n",
    "\n",
    "    vx, vy, ax, ay, speed, accel = compute_derivatives(x, y)\n",
    "\n",
    "    X = []\n",
    "    valid_frames = []\n",
    "\n",
    "    for t in range(3, len(x) - 3):\n",
    "        feats = [\n",
    "            y[t],\n",
    "            vx[t], vy[t],\n",
    "            ax[t], ay[t],\n",
    "            speed[t],\n",
    "            accel[t],\n",
    "            vy[t] - vy[t-1],\n",
    "            speed[t+1] - speed[t],\n",
    "        ]\n",
    "\n",
    "        for w in windows:\n",
    "            feats.extend(sliding_window_stats(speed, t, w))\n",
    "            feats.extend(sliding_window_stats(accel, t, w))\n",
    "            feats.extend(sliding_window_stats(vy, t, w))\n",
    "\n",
    "        X.append(feats)\n",
    "        valid_frames.append(t)\n",
    "\n",
    "    return np.array(X), valid_frames, frame_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb66a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_events_unsupervised(X, contamination=0.03):\n",
    "    \"\"\"\n",
    "    Unsupervised anomaly detection.\n",
    "    Returns indices of anomalous frames (relative to X).\n",
    "    \"\"\"\n",
    "    model = IsolationForest(\n",
    "        n_estimators=200,\n",
    "        contamination=contamination,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    model.fit(X)\n",
    "    preds = model.predict(X)   # -1 = anomaly\n",
    "    return np.where(preds == -1)[0]\n",
    "\n",
    "\n",
    "def cluster_events(frame_indices, eps=5):\n",
    "    \"\"\"\n",
    "    Temporal clustering of anomalies.\n",
    "    \"\"\"\n",
    "    if len(frame_indices) == 0:\n",
    "        return []\n",
    "\n",
    "    X = frame_indices.reshape(-1, 1)\n",
    "    labels = DBSCAN(eps=eps, min_samples=1).fit_predict(X)\n",
    "\n",
    "    centers = []\n",
    "    for lab in np.unique(labels):\n",
    "        cluster = frame_indices[labels == lab]\n",
    "        centers.append(int(np.median(cluster)))\n",
    "\n",
    "    return sorted(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6a7d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_events(event_frames, y, vy, speed, accel):\n",
    "    \"\"\"\n",
    "    Physics-based hit vs bounce.\n",
    "    \"\"\"\n",
    "    bounce = []\n",
    "    hit = []\n",
    "\n",
    "    accel_thr = np.percentile(accel, 80)\n",
    "    y_ground = np.percentile(y, 70)\n",
    "\n",
    "    for t in event_frames:\n",
    "        if t < 2 or t > len(y) - 3:\n",
    "            continue\n",
    "\n",
    "        # Bounce conditions\n",
    "        is_bounce = (\n",
    "            vy[t-1] > 0 and vy[t+1] < 0 and\n",
    "            y[t] >= y_ground and\n",
    "            accel[t] > accel_thr\n",
    "        )\n",
    "\n",
    "        if is_bounce:\n",
    "            bounce.append(t)\n",
    "        else:\n",
    "            hit.append(t)\n",
    "\n",
    "    return bounce, hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9975547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_hit_bounce_detection(ball_data):\n",
    "    X, valid_frames, frame_ids = build_features(ball_data)\n",
    "\n",
    "    anomaly_idx = detect_events_unsupervised(X)\n",
    "    anomaly_frames = np.array(valid_frames)[anomaly_idx]\n",
    "\n",
    "    event_centers = cluster_events(anomaly_frames)\n",
    "\n",
    "    # Recompute trajectories for physics\n",
    "    x = np.array([ball_data[f][\"x\"] for f in frame_ids], dtype=float)\n",
    "    y = np.array([ball_data[f][\"y\"] for f in frame_ids], dtype=float)\n",
    "    vy = np.gradient(y)\n",
    "    speed = np.sqrt(np.gradient(x)**2 + np.gradient(y)**2)\n",
    "    accel = np.gradient(speed)\n",
    "\n",
    "    bounce, hit = classify_events(event_centers, y, vy, speed, accel)\n",
    "\n",
    "    bounce_set = set(bounce)\n",
    "    hit_set = set(hit)\n",
    "\n",
    "    for i, fid in enumerate(frame_ids):\n",
    "        if i in bounce_set:\n",
    "            ball_data[fid][\"pred_action\"] = \"bounce\"\n",
    "        elif i in hit_set:\n",
    "            ball_data[fid][\"pred_action\"] = \"hit\"\n",
    "        else:\n",
    "            ball_data[fid][\"pred_action\"] = \"air\"\n",
    "\n",
    "    return ball_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c87331ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(ball_data):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for f in sorted(ball_data.keys(), key=lambda x: int(x)):\n",
    "        y_true.append(ball_data[f][\"action\"])\n",
    "        y_pred.append(ball_data[f][\"pred_action\"])\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32bb753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "GLOBAL MATCH EVALUATION\n",
      "===================================\n",
      "Number of points  : 313\n",
      "Number of frames  : 177341\n",
      "\n",
      "Classification report (global):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         air      0.984     0.996     0.990    174295\n",
      "         hit      0.292     0.163     0.209      1600\n",
      "      bounce      0.000     0.000     0.000      1446\n",
      "\n",
      "    accuracy                          0.981    177341\n",
      "   macro avg      0.425     0.387     0.400    177341\n",
      "weighted avg      0.970     0.981     0.975    177341\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[173679    616      0]\n",
      " [  1339    261      0]\n",
      " [  1428     18      0]]\n"
     ]
    }
   ],
   "source": [
    "input_dir = Path(\n",
    "    \"Data hit & bounce/per_point_v2\"\n",
    ")\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "n_points = 0\n",
    "n_frames = 0\n",
    "\n",
    "for json_path in input_dir.glob(\"*.json\"):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        ball_data = json.load(f)\n",
    "\n",
    "    ball_data = unsupervised_hit_bounce_detection(ball_data)\n",
    "\n",
    "    for k in ball_data.keys():\n",
    "        y_true_all.append(ball_data[k][\"action\"])\n",
    "        y_pred_all.append(ball_data[k][\"pred_action\"])\n",
    "        n_frames += 1\n",
    "\n",
    "    n_points += 1\n",
    "\n",
    "print(\"===================================\")\n",
    "print(\"GLOBAL MATCH EVALUATION\")\n",
    "print(\"===================================\")\n",
    "print(f\"Number of points  : {n_points}\")\n",
    "print(f\"Number of frames  : {n_frames}\")\n",
    "print()\n",
    "\n",
    "print(\"Classification report (global):\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true_all,\n",
    "        y_pred_all,\n",
    "        labels=[\"air\", \"hit\", \"bounce\"],\n",
    "        digits=3,\n",
    "        zero_division=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "print(\n",
    "    confusion_matrix(\n",
    "        y_true_all,\n",
    "        y_pred_all,\n",
    "        labels=[\"air\", \"hit\", \"bounce\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0ac4f",
   "metadata": {},
   "source": [
    "The unsupervised physics-based method correctly identifies candidate event regions, but fails at exact frame-level classification due to extreme class imbalance and the impulse-like nature of hits and bounces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826d8983",
   "metadata": {},
   "source": [
    "This motivated the supervised sliding-window approach, which learns temporal context instead of relying on local derivatives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
