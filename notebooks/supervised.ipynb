{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688ea19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (113673, 12)\n",
      "label\n",
      "air       110627\n",
      "hit         1600\n",
      "bounce      1446\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Supervised ML — RandomForest Baseline ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         air       1.00      0.54      0.70     22126\n",
      "      bounce       0.29      0.51      0.37       289\n",
      "         hit       0.03      0.93      0.06       320\n",
      "\n",
      "    accuracy                           0.54     22735\n",
      "   macro avg       0.44      0.66      0.38     22735\n",
      "weighted avg       0.97      0.54      0.69     22735\n",
      "\n",
      "[[11902   354  9870]\n",
      " [   30   148   111]\n",
      " [   22     1   297]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Feature engineering (same as V3, but simplified)\n",
    "# ======================================================\n",
    "\n",
    "def compute_features(x, y, window=15, poly=3):\n",
    "    \"\"\"Smooth + derivatives + physics-based features\"\"\"\n",
    "\n",
    "    # Savitzky-Golay smoothing\n",
    "    x_s = savgol_filter(x, window, poly)\n",
    "    y_s = savgol_filter(y, window, poly)\n",
    "\n",
    "    vx = np.gradient(x_s)\n",
    "    vy = np.gradient(y_s)\n",
    "    ax = np.gradient(vx)\n",
    "    ay = np.gradient(vy)\n",
    "\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    accel = np.sqrt(ax**2 + ay**2)\n",
    "    jerk = np.gradient(accel)\n",
    "\n",
    "    angle = np.degrees(np.arctan2(vy, vx))\n",
    "    angle_change = np.gradient(angle)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"x\": x_s,\n",
    "        \"y\": y_s,\n",
    "        \"vx\": vx,\n",
    "        \"vy\": vy,\n",
    "        \"ax\": ax,\n",
    "        \"ay\": ay,\n",
    "        \"speed\": speed,\n",
    "        \"accel\": accel,\n",
    "        \"jerk\": jerk,\n",
    "        \"angle\": angle,\n",
    "        \"angle_change\": angle_change,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Load per-point JSON → create ML dataset\n",
    "# ======================================================\n",
    "\n",
    "def load_all_points(folder: Path):\n",
    "    rows = []\n",
    "\n",
    "    for file in folder.glob(\"*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        frames = sorted(data.keys(), key=lambda x: int(x))\n",
    "\n",
    "        x = np.array([data[f][\"x\"] for f in frames], dtype=float)\n",
    "        y = np.array([data[f][\"y\"] for f in frames], dtype=float)\n",
    "        visible = np.array([data[f][\"visible\"] for f in frames], dtype=bool)\n",
    "        action = [data[f][\"action\"] for f in frames]\n",
    "\n",
    "        # Only keep visible points (or keep all? choose option A)\n",
    "        valid = visible  # OPTION A\n",
    "\n",
    "        # Compute features\n",
    "        feats = compute_features(x, y)\n",
    "\n",
    "        for i in range(len(frames)):\n",
    "            if not valid[i]:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                **feats.iloc[i].to_dict(),\n",
    "                \"label\": action[i]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Baseline ML model\n",
    "# ======================================================\n",
    "\n",
    "def train_supervised_baseline(df):\n",
    "\n",
    "    X = df.drop(columns=[\"label\"])\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=True, stratify=y\n",
    "    )\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        class_weight=\"balanced\",\n",
    "        max_depth=12,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"\\n=== Supervised ML — RandomForest Baseline ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# MAIN\n",
    "# ======================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder = Path(\"/Users/noeamar/Documents/M2DS/Stage M2DS/Quantum Sports Analytics/Data hit & bounce/per_point_v2\")\n",
    "\n",
    "    df = load_all_points(folder)\n",
    "    print(\"Dataset shape:\", df.shape)\n",
    "    print(df[\"label\"].value_counts())\n",
    "\n",
    "    model = train_supervised_baseline(df)\n",
    "\n",
    "    # Save the model?\n",
    "    # import joblib\n",
    "    # joblib.dump(model, \"rf_supervised.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586c8f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Number of training windows: 112091\n",
      "Shape X: (112091, 165)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noeamar/Documents/M2DS/Stage M2DS/Quantum Sports Analytics/.venv/lib/python3.13/site-packages/xgboost/training.py:199: UserWarning: [18:46:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Sliding Window + XGBoost ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         air       0.98      1.00      0.99     21828\n",
      "      bounce       0.72      0.41      0.52       282\n",
      "         hit       0.84      0.17      0.28       309\n",
      "\n",
      "    accuracy                           0.98     22419\n",
      "   macro avg       0.85      0.53      0.60     22419\n",
      "weighted avg       0.98      0.98      0.97     22419\n",
      "\n",
      "[[21775    43    10]\n",
      " [  166   116     0]\n",
      " [  254     3    52]]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Feature computation (same as before)\n",
    "# ============================================================\n",
    "\n",
    "def compute_features(x, y, window=15, poly=3):\n",
    "    x_s = savgol_filter(x, window, poly)\n",
    "    y_s = savgol_filter(y, window, poly)\n",
    "\n",
    "    vx = np.gradient(x_s)\n",
    "    vy = np.gradient(y_s)\n",
    "    ax = np.gradient(vx)\n",
    "    ay = np.gradient(vy)\n",
    "\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    accel = np.sqrt(ax**2 + ay**2)\n",
    "    jerk = np.gradient(accel)\n",
    "\n",
    "    angle = np.degrees(np.arctan2(vy, vx))\n",
    "    angle_change = np.gradient(angle)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"x\": x_s, \"y\": y_s,\n",
    "        \"vx\": vx, \"vy\": vy,\n",
    "        \"ax\": ax, \"ay\": ay,\n",
    "        \"speed\": speed,\n",
    "        \"accel\": accel,\n",
    "        \"jerk\": jerk,\n",
    "        \"angle\": angle,\n",
    "        \"angle_change\": angle_change,\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Load all files and build sliding window dataset\n",
    "# ============================================================\n",
    "\n",
    "def load_dataset_with_windows(folder: Path, W=7):\n",
    "    rows = []\n",
    "    half = W\n",
    "\n",
    "    for file in folder.glob(\"*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        frames = sorted(data.keys(), key=lambda x: int(x))\n",
    "\n",
    "        x = np.array([data[f][\"x\"] for f in frames], dtype=float)\n",
    "        y = np.array([data[f][\"y\"] for f in frames], dtype=float)\n",
    "        visible = np.array([data[f][\"visible\"] for f in frames], dtype=bool)\n",
    "        labels = np.array([data[f][\"action\"] for f in frames])\n",
    "\n",
    "        # compute physics features\n",
    "        feats = compute_features(x, y)\n",
    "\n",
    "        # build sliding windows\n",
    "        for t in range(half, len(frames) - half):\n",
    "            if not visible[t]:\n",
    "                continue\n",
    "\n",
    "            window_feats = feats.iloc[t-half:t+half+1].values.flatten()\n",
    "\n",
    "            rows.append({\n",
    "                \"features\": window_feats,\n",
    "                \"label\": labels[t],\n",
    "            })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Extract matrix\n",
    "# ============================================================\n",
    "\n",
    "def build_matrix(rows):\n",
    "    X = np.stack([r[\"features\"] for r in rows])\n",
    "    y = np.array([r[\"label\"] for r in rows])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. Training with XGBoost\n",
    "# ============================================================\n",
    "\n",
    "def train_xgb(X, y):\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=3,\n",
    "        tree_method=\"hist\",\n",
    "        scale_pos_weight=None,\n",
    "        gamma=0.0,\n",
    "        reg_lambda=1.2,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    model.set_params(**{\n",
    "        \"class_weight\": \"balanced\"\n",
    "    })\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    folder = Path(\"/Users/noeamar/Documents/M2DS/Stage M2DS/Quantum Sports Analytics/Data hit & bounce/per_point_v2\")\n",
    "\n",
    "    print(\"Loading dataset...\")\n",
    "    rows = load_dataset_with_windows(folder, W=7)   # window size = 15 frames\n",
    "    print(f\"Number of training windows: {len(rows)}\")\n",
    "\n",
    "    X, y = build_matrix(rows)\n",
    "    print(\"Shape X:\", X.shape)\n",
    "\n",
    "    # encode labels\n",
    "    mapping = {\"air\": 0, \"bounce\": 1, \"hit\": 2}\n",
    "    y = np.array([mapping[z] for z in y])\n",
    "\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=True, stratify=y\n",
    "    )\n",
    "\n",
    "    model = train_xgb(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    reverse = {0: \"air\", 1: \"bounce\", 2: \"hit\"}\n",
    "    y_test_str = [reverse[z] for z in y_test]\n",
    "    preds_str = [reverse[z] for z in preds]\n",
    "\n",
    "    print(\"\\n=== Sliding Window + XGBoost ===\")\n",
    "    print(classification_report(y_test_str, preds_str))\n",
    "    print(confusion_matrix(y_test_str, preds_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff5b00b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading multi-window dataset...\n",
      "Number of training windows: 108725\n",
      "Shape X: (108725, 803)\n",
      "\n",
      "=== Multi-Window XGBoost ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         air       0.99      0.98      0.99     21170\n",
      "      bounce       0.54      0.64      0.59       275\n",
      "         hit       0.40      0.60      0.48       300\n",
      "\n",
      "    accuracy                           0.97     21745\n",
      "   macro avg       0.65      0.74      0.69     21745\n",
      "weighted avg       0.98      0.97      0.97     21745\n",
      "\n",
      "[[20757   144   269]\n",
      " [   98   176     1]\n",
      " [  116     3   181]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "supervised_sliding_xgb_multiwindow.py\n",
    "\n",
    "Supervised model for hit/bounce detection using:\n",
    "    • Multi-window temporal embeddings\n",
    "    • Savitzky–Golay derivative features\n",
    "    • XGBoost classifier (multi-class)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. Feature computation (smooth + derivatives)\n",
    "# ============================================================\n",
    "\n",
    "def compute_features(x, y, window=15, poly=3):\n",
    "    \"\"\"Compute smooth features & derivatives.\"\"\"\n",
    "\n",
    "    # Smooth x,y\n",
    "    x_s = savgol_filter(x, window, poly)\n",
    "    y_s = savgol_filter(y, window, poly)\n",
    "\n",
    "    # Velocity & accel\n",
    "    vx = np.gradient(x_s)\n",
    "    vy = np.gradient(y_s)\n",
    "    ax = np.gradient(vx)\n",
    "    ay = np.gradient(vy)\n",
    "\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    accel = np.sqrt(ax**2 + ay**2)\n",
    "    jerk = np.gradient(accel)\n",
    "\n",
    "    angle = np.degrees(np.arctan2(vy, vx))\n",
    "    angle_change = np.gradient(angle)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"x\": x_s, \"y\": y_s,\n",
    "        \"vx\": vx, \"vy\": vy,\n",
    "        \"ax\": ax, \"ay\": ay,\n",
    "        \"speed\": speed,\n",
    "        \"accel\": accel,\n",
    "        \"jerk\": jerk,\n",
    "        \"angle\": angle,\n",
    "        \"angle_change\": angle_change,\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Multi Window Construction\n",
    "# ============================================================\n",
    "\n",
    "def build_multiwindow_features(feats_df, t, windows=[5,10,20]):\n",
    "    \"\"\"Build concatenated temporal embedding for multiple window sizes.\"\"\"\n",
    "    vectors = []\n",
    "    T = len(feats_df)\n",
    "\n",
    "    for W in windows:\n",
    "        half = W\n",
    "        if t-half < 0 or t+half >= T:\n",
    "            return None\n",
    "\n",
    "        vec = feats_df.iloc[t-half:t+half+1].values.flatten()\n",
    "        vectors.append(vec)\n",
    "\n",
    "    return np.concatenate(vectors)\n",
    "\n",
    "\n",
    "def load_dataset_multiwindow(folder, windows=[5,10,20]):\n",
    "    rows = []\n",
    "\n",
    "    for file in folder.glob(\"*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        frames = sorted(data.keys(), key=lambda x: int(x))\n",
    "        x = np.array([data[f][\"x\"] for f in frames], dtype=float)\n",
    "        y = np.array([data[f][\"y\"] for f in frames], dtype=float)\n",
    "        labels = np.array([data[f][\"action\"] for f in frames])\n",
    "        visible = np.array([data[f][\"visible\"] for f in frames])\n",
    "\n",
    "        feats = compute_features(x, y)\n",
    "\n",
    "        T = len(frames)\n",
    "        max_half = max(windows)\n",
    "\n",
    "        for t in range(max_half, T-max_half):\n",
    "            if not visible[t]:\n",
    "                continue\n",
    "\n",
    "            fvec = build_multiwindow_features(feats, t, windows)\n",
    "            if fvec is None:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"features\": fvec,\n",
    "                \"label\": labels[t],\n",
    "            })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Build X, y matrices\n",
    "# ============================================================\n",
    "\n",
    "def build_matrix(rows):\n",
    "    X = np.stack([r[\"features\"] for r in rows])\n",
    "    y = np.array([r[\"label\"] for r in rows])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. XGBoost training\n",
    "# ============================================================\n",
    "\n",
    "def train_xgb(X_train, y_train):\n",
    "    \"\"\"XGBoost for multi-class classification with weighted classes.\"\"\"\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=3,\n",
    "        tree_method=\"hist\",\n",
    "        reg_lambda=1.0,\n",
    "        gamma=0.0,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # Class imbalance handled via sample weighting (manual)\n",
    "    weights = np.ones_like(y_train, dtype=float)\n",
    "    weights[y_train == 1] *= 15.0   # bounce\n",
    "    weights[y_train == 2] *= 15.0   # hit\n",
    "\n",
    "    model.fit(X_train, y_train, sample_weight=weights)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    folder = Path(\"/Users/noeamar/Documents/M2DS/Stage M2DS/Quantum Sports Analytics/Data hit & bounce/per_point_v2\")\n",
    "\n",
    "    print(\"Loading multi-window dataset...\")\n",
    "    rows = load_dataset_multiwindow(folder, windows=[5, 10, 20])\n",
    "    print(f\"Number of training windows: {len(rows)}\")\n",
    "\n",
    "    X, y = build_matrix(rows)\n",
    "    print(\"Shape X:\", X.shape)\n",
    "\n",
    "    # Encode labels\n",
    "    mapping = {\"air\": 0, \"bounce\": 1, \"hit\": 2}\n",
    "    y = np.array([mapping[z] for z in y])\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        stratify=y,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    model = train_xgb(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    reverse = {0:\"air\", 1:\"bounce\", 2:\"hit\"}\n",
    "    y_test_str = [reverse[z] for z in y_test]\n",
    "    preds_str = [reverse[z] for z in preds]\n",
    "\n",
    "    print(\"\\n=== Multi-Window XGBoost ===\")\n",
    "    print(classification_report(y_test_str, preds_str))\n",
    "    print(confusion_matrix(y_test_str, preds_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dbf4a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading multi-window dataset...\n",
      "Number of windows: 105781\n",
      "Shape X: (105781, 2546)\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.583139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 649229\n",
      "[LightGBM] [Info] Number of data points in the train set: 84624, number of used features: 2546\n",
      "[LightGBM] [Info] Start training from score -0.027009\n",
      "[LightGBM] [Info] Start training from score -4.353877\n",
      "[LightGBM] [Info] Start training from score -4.283782\n",
      "\n",
      "=== LightGBM Multi-Window + RAW + Smooth ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         air       0.99      1.00      1.00     20593\n",
      "      bounce       0.93      0.82      0.87       272\n",
      "         hit       0.85      0.68      0.75       292\n",
      "\n",
      "    accuracy                           0.99     21157\n",
      "   macro avg       0.92      0.83      0.87     21157\n",
      "weighted avg       0.99      0.99      0.99     21157\n",
      "\n",
      "[[20544    13    36]\n",
      " [   50   222     0]\n",
      " [   91     3   198]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "supervised_lightgbm_multiwindow.py\n",
    "\n",
    "LightGBM + Multi-windows + RAW + Smooth features.\n",
    "Best performing supervised baseline for hit/bounce detection.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. RAW + SMOOTH feature extraction\n",
    "# ============================================================\n",
    "\n",
    "def compute_raw_smooth_features(x, y, sg_window=15, poly=3):\n",
    "    \"\"\"Return BOTH raw and smooth derivative features.\"\"\"\n",
    "\n",
    "    # RAW\n",
    "    vx_raw = np.gradient(x)\n",
    "    vy_raw = np.gradient(y)\n",
    "    ax_raw = np.gradient(vx_raw)\n",
    "    ay_raw = np.gradient(vy_raw)\n",
    "    speed_raw = np.sqrt(vx_raw**2 + vy_raw**2)\n",
    "    accel_raw = np.sqrt(ax_raw**2 + ay_raw**2)\n",
    "\n",
    "    # SMOOTH\n",
    "    x_s = savgol_filter(x, sg_window, poly)\n",
    "    y_s = savgol_filter(y, sg_window, poly)\n",
    "\n",
    "    vx = np.gradient(x_s)\n",
    "    vy = np.gradient(y_s)\n",
    "    ax = np.gradient(vx)\n",
    "    ay = np.gradient(vy)\n",
    "    speed = np.sqrt(vx**2 + vy**2)\n",
    "    accel = np.sqrt(ax**2 + ay**2)\n",
    "    jerk = np.gradient(accel)\n",
    "\n",
    "    angle = np.degrees(np.arctan2(vy, vx))\n",
    "    angle_change = np.gradient(angle)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        # RAW\n",
    "        \"x_raw\": x, \"y_raw\": y,\n",
    "        \"vx_raw\": vx_raw, \"vy_raw\": vy_raw,\n",
    "        \"ax_raw\": ax_raw, \"ay_raw\": ay_raw,\n",
    "        \"speed_raw\": speed_raw, \"accel_raw\": accel_raw,\n",
    "\n",
    "        # SMOOTH\n",
    "        \"x_s\": x_s, \"y_s\": y_s,\n",
    "        \"vx_s\": vx, \"vy_s\": vy,\n",
    "        \"ax_s\": ax, \"ay_s\": ay,\n",
    "        \"speed_s\": speed,\n",
    "        \"accel_s\": accel,\n",
    "        \"jerk_s\": jerk,\n",
    "        \"angle_s\": angle,\n",
    "        \"angle_change_s\": angle_change,\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. Multi-window temporal embedding\n",
    "# ============================================================\n",
    "\n",
    "def build_multiwindow_features(df, t, windows):\n",
    "    vectors = []\n",
    "    T = len(df)\n",
    "\n",
    "    for W in windows:\n",
    "        half = W\n",
    "        if t-half < 0 or t+half >= T:\n",
    "            return None\n",
    "\n",
    "        vec = df.iloc[t-half:t+half+1].values.flatten()\n",
    "        vectors.append(vec)\n",
    "\n",
    "    return np.concatenate(vectors)\n",
    "\n",
    "\n",
    "def load_dataset_multiwindow(folder, windows=[5,10,20,30]):\n",
    "    rows = []\n",
    "\n",
    "    for file in folder.glob(\"*.json\"):\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        frames = sorted(data.keys(), key=lambda x: int(x))\n",
    "        x = np.array([data[f][\"x\"] for f in frames], float)\n",
    "        y = np.array([data[f][\"y\"] for f in frames], float)\n",
    "        labels = np.array([data[f][\"action\"] for f in frames])\n",
    "        visible = np.array([data[f][\"visible\"] for f in frames])\n",
    "\n",
    "        feats = compute_raw_smooth_features(x, y)\n",
    "\n",
    "        T = len(frames)\n",
    "        max_half = max(windows)\n",
    "\n",
    "        for t in range(max_half, T-max_half):\n",
    "            if not visible[t]:\n",
    "                continue\n",
    "\n",
    "            fv = build_multiwindow_features(feats, t, windows)\n",
    "            if fv is None:\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                \"features\": fv,\n",
    "                \"label\": labels[t],\n",
    "            })\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. Build matrices\n",
    "# ============================================================\n",
    "\n",
    "def build_matrix(rows):\n",
    "    X = np.stack([r[\"features\"] for r in rows])\n",
    "    y = np.array([r[\"label\"] for r in rows])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. LightGBM training\n",
    "# ============================================================\n",
    "\n",
    "def train_lgbm(X_train, y_train):\n",
    "    \"\"\"Train LightGBM for multi-class (3 classes).\"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",\n",
    "        \"num_class\": 3,\n",
    "        \"metric\": \"multi_logloss\",\n",
    "\n",
    "        # Strong model\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 64,\n",
    "        \"max_depth\": -1,\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"feature_fraction\": 0.9,\n",
    "        \"bagging_fraction\": 0.8,\n",
    "        \"bagging_freq\": 1,\n",
    "        \"lambda_l2\": 1.0,\n",
    "    }\n",
    "\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    model = lgb.train(params, dtrain, num_boost_round=600)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    folder = Path(\"/Users/noeamar/Documents/M2DS/Stage M2DS/Quantum Sports Analytics/Data hit & bounce/per_point_v2\")\n",
    "\n",
    "    print(\"Loading multi-window dataset...\")\n",
    "    rows = load_dataset_multiwindow(folder, windows=[5,10,20,30])\n",
    "    print(f\"Number of windows: {len(rows)}\")\n",
    "\n",
    "    X, y = build_matrix(rows)\n",
    "    print(\"Shape X:\", X.shape)\n",
    "\n",
    "    mapping = {\"air\": 0, \"bounce\": 1, \"hit\": 2}\n",
    "    y = np.array([mapping[z] for z in y])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=True, stratify=y, random_state=0\n",
    "    )\n",
    "\n",
    "    print(\"Training LightGBM...\")\n",
    "    model = train_lgbm(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    reverse = {0:\"air\", 1:\"bounce\", 2:\"hit\"}\n",
    "    y_test_str = [reverse[z] for z in y_test]\n",
    "    preds_str = [reverse[z] for z in preds]\n",
    "\n",
    "    print(\"\\n=== LightGBM Multi-Window + RAW + Smooth ===\")\n",
    "    print(classification_report(y_test_str, preds_str))\n",
    "    print(confusion_matrix(y_test_str, preds_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
